{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ac1497",
   "metadata": {},
   "source": [
    "# Final use-case : School Failure Prediction\n",
    "\n",
    "This notebook will try to build a **predictive ai solution** to estimate a school failure for a given student.\n",
    "\n",
    "The system use a \"*Chain of Responsibiliy*\" pattern to pipeline the process. Each element of the chain is responsible of one process, then give the result to the other.\n",
    "\n",
    "This architecture allow to easily change or add process orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7660be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "from core.pipeline_core.pipeline_core import DataHandler, PipelineContext, PipelineOrchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76fd24",
   "metadata": {},
   "source": [
    "*Refactorization*\n",
    "Handlers are removed from the book :\n",
    "- DataLoader is now in the core.handlers package (data_loader.py),\n",
    "- SensitiveDataHandler moved to core.handlers package (sensitive_data_handler.py)\n",
    "- MergerHandler moved to core.handlers package (merger_handler.py)\n",
    "- OutlierHandler moved to core.handlers package (outlier_handler.py)\n",
    "- ImputationHandler moved to core.handlers package (imputation_handler.py)\n",
    "- DataExportHandler moved to core.handlers package (data_export_handler.py),\n",
    "- ModelHandler moved to core.handlers package (model_handler.py)\n",
    "\n",
    "**Notes** :\n",
    "\n",
    "*Outlier handler :*\n",
    "Handle *outliers* using strategies :\n",
    "- IQR,\n",
    "- Isolation Forest\n",
    "Finally removes the entire line if one cols is ludicurious\n",
    "\n",
    "*NaN imputation :*\n",
    "Identity NaN values from the dataframe. Use different strategies for replacement :\n",
    "- AIImputation : Using regression to identify NaN (usefull for large dataframe)\n",
    "- SimpleImputer : Using either mean or median replacement strategy\n",
    "\n",
    "*Model Handler* :\n",
    "ModelHandler use *strategies*: \n",
    "- Logistic Regression - LR,\n",
    "- Random Forest Classifier - RF \n",
    "\n",
    "and use 4 base hypothesis : full_dataframe, no sensitive data, no_g1, no_g1_g2\n",
    "\n",
    "The pipeline scheme sets in a YAML config can be tuned to :\n",
    "- Add other algorithms,\n",
    "- Sets different hypothesis\n",
    "\n",
    "During training MLFlow is used to store parameters, artifacts and final models.\n",
    "\n",
    "## Move orchestration logic to YAML configuration\n",
    "Using configuration, we offer the possibility to handle steps dynamically. The following class read configuration and build the orchestration.\n",
    "\n",
    "**PipelineBuilder** moved to core.pipeline_core package (pipeline_builder.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511dc97",
   "metadata": {},
   "source": [
    "## Orchestrator settings (@Deprecated)\n",
    "- Sets sources,\n",
    "- Sets sensitive datas,\n",
    "- Initiate orchestrator\n",
    "\n",
    "**Deprecated** after delegating to PiplelineBuilder, there's no need to manually configure the orchestrator.\n",
    "\n",
    "Kept only here for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.handlers.data_export_handler import DataExportHandler\n",
    "from core.handlers.data_loader import DataLoader\n",
    "from core.handlers.imputation_handler import ImputationHandler\n",
    "from core.handlers.merger_handler import MergerHandler\n",
    "from core.handlers.model_handler import ModelHandler\n",
    "from core.handlers.outlier_handler import OutlierHandler\n",
    "from core.handlers.sensitive_data_handler import SensitiveDataHandler\n",
    "from core.strategy_core.outliers_strategies import IsolationForestStrategy\n",
    "from core.strategy_core.imputation_strategies import AIImputationStrategy\n",
    "\n",
    "files_to_load = {\n",
    "    \"maths\": \"datas/student-mat.csv\",\n",
    "    \"por\": \"datas/student-por.csv\"\n",
    "}\n",
    "\n",
    "sensitives = [\n",
    "    \"romantic\", # No correlation\n",
    "    \"Dalc\", # Discriminant data, cannot be used\n",
    "    \"Walc\", # Discrimant data, cannot be used\n",
    "]\n",
    "\n",
    "# Make chain instances :\n",
    "# 1. Data processing chain\n",
    "loader = DataLoader(files_to_load=files_to_load)\n",
    "cleaner = SensitiveDataHandler(sensitive_columns=sensitives)\n",
    "merger = MergerHandler()\n",
    "\n",
    "# Sets one of the Outliers detection strategy (Isolation Forest)\n",
    "outlier_strategy = IsolationForestStrategy(contamination=0.01)\n",
    "outlier = OutlierHandler(strategy=outlier_strategy, target_columns=[\"studytime\", \"absences\", \"age\"])\n",
    "\n",
    "# Sets one of the Imputation Strategy\n",
    "imputer_strategy = AIImputationStrategy()\n",
    "imputer = ImputationHandler(imputer_strategy)\n",
    "\n",
    "exporter = DataExportHandler()\n",
    "\n",
    "# Instanciate Pipeline\n",
    "pipeline = (PipelineOrchestrator()\n",
    "    .add_handler(loader)\n",
    "    .add_handler(cleaner)\n",
    "    .add_handler(merger)\n",
    "    .add_handler(outlier)\n",
    "    .add_handler(imputer)\n",
    "    .add_handler(exporter)\n",
    ")\n",
    "\n",
    "# 2. Learning processing\n",
    "scenarii = [\n",
    "    (1, \"Full_Features\", []),\n",
    "    (2, \"No_Sensitive\", [\"romantic\", \"Dalc\", \"Walc\"]),\n",
    "    (3, \"No_Sensitive_No_G2\", [\"romantic\", \"Dalc\", \"Walc\", \"G2\"]),\n",
    "    (4, \"No_Sensitive_No_G1_G2\", [\"romantic\", \"Dalc\", \"Walc\", \"G1\", \"G2\"])\n",
    "]\n",
    "from core.strategy_core.training_strategies import LogisticRegressionStrategy\n",
    "from core.strategy_core.training_strategies import RandomForestStrategy\n",
    "# 2.1 From definitions add strategies needed\n",
    "for s_id, s_name, s_exclusions in scenarii:\n",
    "    for strategy_class in [LogisticRegressionStrategy, RandomForestStrategy]:\n",
    "        strategy = strategy_class(scenario_id=s_name, exclusions=s_exclusions)\n",
    "        model_handler = ModelHandler(strategy=strategy, scenario_label=s_name)\n",
    "        pipeline.add_handler(model_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae9019",
   "metadata": {},
   "source": [
    "## Run orchestrator\n",
    "\n",
    "Orchestrator is a Chain of Responsibilies. At the end of the chain, all processes are done.\n",
    "\n",
    "**Major update** : delegate chain assembly in a configuration file (see : pipeline_config.yml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize context and orchestrator\n",
    "from core.pipeline_core.pipeline_builder import PipelineBuilder\n",
    "\n",
    "\n",
    "orchestrator = PipelineOrchestrator()\n",
    "context = PipelineContext()\n",
    "\n",
    "# Build pipeline from Notebook classes and YAML config\n",
    "pipeline = PipelineBuilder.build_from_yaml(\"pipeline_config.yaml\", orchestrator)\n",
    "\n",
    "# Run the pipeline\n",
    "try:\n",
    "    final_context = orchestrator.run(context)\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Pipeline failed: {e}\")\n",
    "finally:\n",
    "    print(\"üèÅ Pipeline execution ended.\")\n",
    "    \n",
    "    # Final report\n",
    "    print(\"\\n--- Merged datas overview ---\")\n",
    "    display(final_context.final_df.head())\n",
    "\n",
    "    print(\"\\n--- Execution stats ---\")\n",
    "    for step, duration in final_context.execution_time.items():\n",
    "        print(f\"{step:25} : {duration:.4f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad780f0",
   "metadata": {},
   "source": [
    "## Store the best run\n",
    "\n",
    "Prepare API exporting the best model (based uppon AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9736d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "models_dir = \"backend/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "for strategy in [\"auc_score\", \"accuracy\"]:\n",
    "    label = \"auc\" if \"auc\" in strategy else \"accuracy\"\n",
    "\n",
    "    # 1. Search for best run\n",
    "    runs = mlflow.search_runs(order_by=[f\"metrics.{strategy} DESC\"])\n",
    "    best_run = runs.iloc[0]\n",
    "    run_id = best_run['run_id']\n",
    "\n",
    "    algo_used = best_run.get(\"tags.algorithm\")\n",
    "    \n",
    "    scenario = best_run.get(\"tags.mlflow.runName\", \"unknown\")\n",
    "    if not algo_used:\n",
    "        algo_used = scenario.split(\"_\")[0] if \"_\" in scenario else \"unknown\"\n",
    "\n",
    "    logger.info(f\"Best run for {label} is {run_id} with scenario {scenario} [{algo_used}]\")\n",
    "    \n",
    "\n",
    "    # 2. Load and save the best model locally\n",
    "    model = mlflow.sklearn.load_model(model_uri=f\"runs:/{run_id}/model\")\n",
    "    joblib.dump(model, f\"backend/models/student_model_{label}_latest.joblib\")\n",
    "    \n",
    "\n",
    "    # 3. Load and save feature names\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    artifacts = [a.path for a in client.list_artifacts(run_id)]\n",
    "    \n",
    "    try:\n",
    "        if \"feature_names.pkl\" in artifacts:\n",
    "            # New format\n",
    "            local_path = client.download_artifacts(run_id, \"feature_names.pkl\", \"backend/models/\")\n",
    "        else:\n",
    "            # Old format\n",
    "            legacy_file = [a for a in artifacts if a.startswith(\"feature_names_\")][0]\n",
    "            local_path = client.download_artifacts(run_id, legacy_file, \"backend/models/\")\n",
    "            \n",
    "        # Renommage final pour l'API\n",
    "        os.rename(local_path, f\"backend/models/feature_names_{label}_latest.pkl\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Impossible de r√©cup√©rer les features pour {run_id}: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ Best model and feature names based on {label} score was saved successfully : {scenario}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (predict)",
   "language": "python",
   "name": "predict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
